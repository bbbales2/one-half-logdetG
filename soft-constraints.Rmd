---
title: "Soft Constraints"
author: "Yuling Yao, Ben Bales"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Change of Variables in Stan

The Stan manual currently only provides guidance for putting a prior on a transformed parameter when there is available a one to one function from the underlying Stan parameters to the transformed parameter.

This is motivated by the statistical change of variables (as documented under [Change of Variables](https://mc-stan.org/docs/2_24/reference-manual/change-of-variables-section.html) in the reference manual).

First assume a Stan program can sample a random variable $Y$ in whatever space it lives. If additionally there is available a one to one transform between $x \in X$ and $y \in Y$, $x = f^{-1}(y)$, where $\det(J_{f^{-1}})$ is well defined everywhere, then a new Stan program can be written to sample $X \sim p_x$.

Stan itself never samples in the coordinate system $X$ lives, it always samples $Y$. To achieve the sampling $X \sim p_x$, a new probability distribution for $Y$ is written in terms of the desired distribution $p_x$ and the transformation $f^{-1}$. This is the familiar statistical change of variables formula:

$$
p_y(y) = p_x(f^{-1}(y)) \det \left( J_{f^{-1}} \right)
$$

This makes it possible to write the Stan programs where transformed parameters are used on the left hand side of distributional statements. For instance, the transform $x = f^{-1}(y) = e^y$ is commonly used to go from an unconstrained random variable $Y$ to one constrained $[0, \infty)$. Assume that a Stan program is needed to sample a $\text{Gamma}(5, 5)$ distribution, which has positive support. Recognizing that the $x$ and $y$ variables here correspond to the equations above, the following Stan program can be used to sample from the appropriate constrained distribution:

```{stan, output.var = "", eval = FALSE}
parameters {
  real y;
}
transformed parameters {
  real x = exp(y);
}
model {
  x ~ gamma(5, 5);
  target += y;
}
```

Similar transforms are how all the basic constrained parameter definitions are handled in Stan. See the Reference Manual section [Constrained Transforms](https://mc-stan.org/docs/2_24/reference-manual/variable-transforms-chapter.html) for more.

## No Change of Variables, but the Variables Changed

There are many other places where transformed parameters are used to define certain priors on parameters in Stan.

As an example, take the common normal distribution:

```{stan, output.var = "", eval = FALSE}
parameters {
  real alpha;
  real mu;
  real<lower = 0.0> sigma;
}
model {
  mu ~ normal(0, 1);
  sigma ~ normal(0, 1);
  alpha ~ normal(mu, sigma);
}
```

The difficulties of sampling such a distribution are well documented ([Diagnosing Biased Inference with Divergences](https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html)).

It is recommended that the model is rewritten in what is called the non-centered form:

```{stan, output.var = "", eval = FALSE}
parameters {
  real z;
  real mu;
  real<lower = 0.0> sigma;
}
transformed parameters {
  real alpha = mu + z * sigma;
}
model {
  mu ~ normal(0, 1);
  sigma ~ normal(0, 1);
  z ~ normal(0, 1);
}
```

In this reparameterization the Stan program no longer directly samples `alpha`, but instead a parameter `z`. `alpha` is defined as a transformed parameter $\alpha = f^{-1}(z) = \mu + z \sigma$. Because $z \sim \text{normal}(0, 1)$, by properties of a linear transformation of a normal random variable, $\alpha$ takes on the desired distribution $\alpha \sim \text{normal}(\mu, \sigma)$.

The other useful technique here is the inverse CDF transformation. If the inverse CDF of a desired distribution is known, then samples from this distribution can be generated by transforming a uniform $[0, 1]$ random variable through the inverse CDF. This is useful for reparameterizing heavy tailed distributions (see [Fitting the Cauchy](https://betanalpha.github.io/assets/case_studies/fitting_the_cauchy.html)) and also thinking about priors in general ([Bayesian Inference without Probability Density Functions](https://www.youtube.com/watch?v=_wfZSvasLFk)).

The point is that all of this is effectively allowing a Stan program to sample a parameter indirectly, and nowhere are the change of variable Jacobians required.

## Intermission

The problem with the two frameworks above is that they only work under very special situations. With a change of variables, to have any control over the trasformed variable it is necessary to have a one to one function with a well behaved Jacobian. Without a change of variables, it is sometimes possible to get the desired transformed variable by just performing a certain transformation on a distribution that is known (a linear transforms of location-scale distributions or an inverse CDF transformations of uniform distributions).

These tools do not help in any situation where more control over the transformed random variable is necessary.

## No Change of Variables, but the Expectations Change

The goal of this case study is to highlight another way that parameter transforms can be used in Stan programs.

One way of looking at an MCMC method is that it is a tool for computing expectations. The average of a function evaluated at the sequence of draws generated from an MCMC method approximates the expectation of that function evaluated over the distribution from which the draws came:

$$
\frac{1}{N}\sum_n^N f(\theta_n) \approx \int_\theta f(\theta) p(\theta) d\theta
$$
A Stan program is simply the $p(\theta)$ part of the expression on the right.

To define the new transformation, first assume there is a high dimensional space $\Theta$ on which the Stan program samples. Then define a lower (or equal) dimensional (constrained) space $C$, and a coordinate chart $\phi : C \rightarrow \theta$.

In this case, it is possible to rewrite an integral over the space $C$ in terms of the space $\Theta$ (https://en.wikipedia.org/wiki/Gramian_matrix):

$$
\int_C g(c) dc = \int_\Theta g(\phi^{-1}(\theta)) \det(\nabla\phi^{-1}\nabla\phi^{-T}) d\theta
$$

In particular, if $g(c) = f(c) p(c)$, then this is an expectation over the constrained space $C$.

$$
E_c[f] = \int_C f(c) p(c) dc = \int_\Theta f(\phi^{-1}(\theta)) p(\phi^{-1}(\theta)) \det(\nabla\phi^{-1}\nabla\phi^{-T}) d\theta
$$

Alright my problem with this is that as far as I can tell on Wikipedia, the coordinate chart $\phi$ has to be one to one, which leaves us in the same boat as the change of variables? What am I doing wrong.